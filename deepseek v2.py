import os
import asyncio
import logging
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from PyPDF2 import PdfReader
import torch
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from openai import OpenAI
from aiogram import Router

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.DEBUG)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()
TOKEN = os.getenv("TELEGRAM_TOKEN")
PDF_FOLDER = os.getenv("PDF_FOLDER")

if not TOKEN:
    raise ValueError("–û—à–∏–±–∫–∞: TELEGRAM_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env!")
if not PDF_FOLDER:
    raise ValueError("–û—à–∏–±–∫–∞: PDF_FOLDER –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env!")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
bot = Bot(token=TOKEN)
dp = Dispatcher()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI
client = OpenAI(
    api_key="sk-aitunnel-v66J7WhiyFEFEu2fQ32zLxgdh77VudJn",
    base_url="https://api.aitunnel.ru/v1/"
)

# –°–æ—Å—Ç–æ—è–Ω–∏—è –±–æ—Ç–∞
class SearchState(StatesGroup):
    searching = State()
    last_result = State()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç
    dialog_context = State()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
async def extract_criteria(user_query):
    messages = [
        {"role": "system", "content": "–¢—ã - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏. –í—ã–¥–µ–ª–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –∫—Ä–∏—Ç–µ—Ä–∏–∏ (–±—é–¥–∂–µ—Ç, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç, –±–∞—Å—Å–µ–π–Ω, —Ä–∞–π–æ–Ω –∏ —Ç. –¥.). –û—Ç–≤–µ—Ç—å JSON-–æ–±—ä–µ–∫—Ç–æ–º."},
        {"role": "user", "content": f"–ö–ª–∏–µ–Ω—Ç –Ω–∞–ø–∏—Å–∞–ª: {user_query}"}
    ]

    response = client.chat.completions.create(
        messages=messages,
        max_tokens=100,
        model="gpt-4o-mini"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à—É –º–æ–¥–µ–ª—å
    )

    criteria_text = response.choices[0].message.content
    try:
        criteria = eval(criteria_text)
    except Exception:
        criteria = {}

    return criteria

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ–±—ä–µ–∫—Ç–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
async def extract_property_details(text):
    messages = [
        {"role": "system", "content": "–¢—ã - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏. –ò–∑–≤–ª–µ–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ü–µ–Ω–µ, –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –∫–æ–º–Ω–∞—Ç, –Ω–∞–ª–∏—á–∏–∏ –±–∞—Å—Å–µ–π–Ω–∞ –∏ –¥—Ä—É–≥–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö. –û—Ç–≤–µ—Ç—å JSON-–æ–±—ä–µ–∫—Ç–æ–º."},
        {"role": "user", "content": f"–¢–µ–∫—Å—Ç: {text}"}
    ]

    response = client.chat.completions.create(
        messages=messages,
        max_tokens=200,
        model="gpt-4o-mini"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à—É –º–æ–¥–µ–ª—å
    )

    details_text = response.choices[0].message.content
    try:
        details = eval(details_text)
    except Exception:
        details = {}

    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–π
    if "pool" not in details:
        details["pool"] = False  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –±–∞—Å—Å–µ–π–Ω –Ω–µ —É–∫–∞–∑–∞–Ω
    if "rooms" not in details:
        details["rooms"] = 0  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç –Ω–µ —É–∫–∞–∑–∞–Ω–æ
    if "price" not in details:
        details["price"] = float("inf")  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ —Ü–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞

    return details

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
async def create_embeddings():
    print("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏...")

    property_data = []
    metadata = []

    for filename in os.listdir(PDF_FOLDER):
        if filename.endswith(".pdf"):
            pdf_path = os.path.join(PDF_FOLDER, filename)
            pdf_reader = PdfReader(pdf_path)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()

            property_data.append(text)
            metadata.append({"filename": filename})

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=100,
        length_function=len
    )

    chunks = []
    meta_list = []
    for text, meta in zip(property_data, metadata):
        prop_chunks = text_splitter.split_text(text)
        chunks.extend(prop_chunks)
        meta_list.extend([meta] * len(prop_chunks))

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={"device": "cuda" if torch.cuda.is_available() else "cpu"}
    )

    knowledge_base = FAISS.from_texts(chunks, embeddings, metadatas=meta_list)
    print("‚úÖ –ë–∞–∑–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    return knowledge_base

# –°–æ–∑–¥–∞—ë–º —Ä–æ—É—Ç–µ—Ä
router = Router()

# –ö–æ–º–∞–Ω–¥–∞ /start
@router.message(Command("start"))
async def start_cmd(message: Message, state: FSMContext):
    await state.clear()  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç-–ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ üè°\n–ö–∞–∫—É—é –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å –≤—ã –∏—â–µ—Ç–µ?")
    await state.set_state(SearchState.searching)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
@router.message(SearchState.searching)
async def handle_search(message: Message, state: FSMContext):
    user_query = message.text

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
    criteria = await extract_criteria(user_query)
    await state.update_data(user_criteria=criteria)

    # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –æ–±—ä–µ–∫—Ç—ã –≤ –±–∞–∑–µ FAISS
    docs = knowledge_base.similarity_search(user_query, k=10) if knowledge_base else []
    print(f"–ù–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {len(docs)}")  # –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥

    # –§–∏–ª—å—Ç—Ä—É–µ–º –æ–±—ä–µ–∫—Ç—ã –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
    filtered_properties = []
    for doc in docs:
        details = await extract_property_details(doc.page_content)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –æ–±—ä–µ–∫—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º
        if (details.get("price", float("inf")) <= criteria.get("budget", float("inf")) and
            details.get("rooms", 0) >= criteria.get("rooms", 0)):
            filtered_properties.append(doc)

    if filtered_properties:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç
        await state.update_data(last_result=filtered_properties[0])

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        properties_text = "\n\n".join([
            f"üè† *{doc.metadata.get('filename', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}*\nüìã {doc.page_content[:250]}..."
            for doc in filtered_properties
        ])

        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
        data = await state.get_data()
        context = data.get("dialog_context", [])

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        response = await generate_ai_response(user_query, properties_text, context)

        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
        context.append({"role": "user", "content": user_query})
        context.append({"role": "assistant", "content": response})
        await state.update_data(dialog_context=context)
    else:
        response = "üòï –ù–µ –Ω–∞—à–µ–ª –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å."

    await message.answer(response, parse_mode="Markdown")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏
#    data = await state.get_data()
#    last_property = data.get("last_result")
#
 #   if last_property:
 #       # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º –Ω–∞–π–¥–µ–Ω–Ω–æ–º –æ–±—ä–µ–∫—Ç–µ
  #      details = await extract_property_details(last_property.page_content)
#
 #       # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
 #       response = f"üìå –í–æ—Ç –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ {last_property.metadata.get('filename', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–º –æ–±—ä–µ–∫—Ç–µ')}:\n\n"
#        
 #       if "price" in details:
   #         response += f"üí∞ –¶–µ–Ω–∞: {details['price']} MXN\n"
 #       if "rooms" in details:
 #           response += f"üõèÔ∏è –ö–æ–º–Ω–∞—Ç: {details['rooms']}\n"
 #       if "location" in details:
  #          response += f"üìç –†–∞–π–æ–Ω: {details['location']}\n"
  #      if "pool" in details:
   #         response += f"üèä –ë–∞—Å—Å–µ–π–Ω: {'–µ—Å—Ç—å' if details['pool'] else '–Ω–µ—Ç'}\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –æ–±—ä–µ–∫—Ç–∞
   #     response += f"\nüìã –û–ø–∏—Å–∞–Ω–∏–µ: {last_property.page_content[:500]}..."
   # else:
    #    response = "üòï –ù–µ –º–æ–≥—É –≤—Å–ø–æ–º–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∏—Å–∫ –∑–∞–Ω–æ–≤–æ."

   # await message.answer(response)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ GPT
async def generate_ai_response(user_query, properties, context):
    messages = [
        {"role": "system", "content": "–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç –ø–æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏.  –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É—è –¥–∞–Ω–Ω—ã–µ –æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ç–µ–±–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã. –ù–µ –¥–∞–≤–∞–π –æ–±—â–∏—Ö —Å–æ–≤–µ—Ç–æ–≤, –µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."},
        *context,  # –ü–µ—Ä–µ–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
        {"role": "user", "content": user_query},
        {"role": "assistant", "content": f"–í–æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤:\n\n{properties}"},
        {"role": "user", "content": "–ù–∞–ø–∏—à–∏ –æ—Ç–≤–µ—Ç –≤ —Å—Ç–∏–ª–µ –¥–µ–ª–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è"}
    ]

    response = client.chat.completions.create(
        messages=messages,
        max_tokens=500,
        model="gpt-4o-mini"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à—É –º–æ–¥–µ–ª—å
    )

    return response.choices[0].message.content

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    global knowledge_base
    print("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏...")
    knowledge_base = await create_embeddings()
    print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º Telegram-–±–æ—Ç–∞...")

    dp.include_router(router)
    await dp.start_polling(bot)

if __name__ == "__main__":
    print("üü¢ –ó–∞–ø—É—Å–∫–∞–µ–º event loop...")
    asyncio.run(main())