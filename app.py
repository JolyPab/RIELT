#=============
#===–ò–º–ø–æ—Ä—Ç—ã===
#=============
import os
import asyncio
import logging
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message, FSInputFile
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from openai import OpenAI
#===============
#===–ù–∞—Å—Ç—Ä–æ–π–∫–∏===
#===============
TOKEN = "8041779345:AAE41dOCSlRCCjL63L-QaS9IghHE9XvQkp0"
PDF_FOLDER = "C:\\Users\\jolypab\\Documents\\CODE\\RIELT\\PDF"


#=====================================
#===–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞===
#=====================================
bot = Bot(token=TOKEN)
dp = Dispatcher()


#===================================
#===–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø—Ä–æ–∫—Å–∏ API OpenAI===
#===================================
client = OpenAI(
    api_key="sk-aitunnel-v66J7WhiyFEFEu2fQ32zLxgdh77VudJn",  # –¢–≤–æ–π API-–∫–ª—é—á
    base_url="https://api.aitunnel.ru/v1/"
)


#===================
#===FSM –°–æ—Å—Ç–æ—è–Ω–∏—è===
#===================
class SearchState(StatesGroup):
    searching = State()

#=====================================================
#===–§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF –∏ —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã===
#=====================================================
def create_embeddings():
    property_data = []
    metadata = []

    for filename in os.listdir(PDF_FOLDER):
        if filename.endswith(".pdf"):
            pdf_path = os.path.join(PDF_FOLDER, filename)
            pdf_reader = PdfReader(pdf_path)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()

            property_data.append(text)
            metadata.append({"filename": filename})

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=100,
        length_function=len
    )

    chunks = []
    meta_list = []
    for text, meta in zip(property_data, metadata):
        prop_chunks = text_splitter.split_text(text)
        chunks.extend(prop_chunks)
        meta_list.extend([meta] * len(prop_chunks))

    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2")
    knowledge_base = FAISS.from_texts(chunks, embeddings, metadatas=meta_list)

    return knowledge_base


#=================================
#===–ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏===
#=================================
knowledge_base = create_embeddings()


#==================================
#===–§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞===
#==================================
async def generate_ai_response(user_query, properties):
    messages = [
        {"role": "system", "content": "–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç –ø–æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏."},
        {"role": "user", "content": f"–ö–ª–∏–µ–Ω—Ç –∏—â–µ—Ç: {user_query}"},
        {"role": "assistant", "content": f"–í–æ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:\n\n{properties}"},
        {"role": "user", "content": "–û—Ç–≤–µ—Ç—å —Ç–∞–∫, –∫–∞–∫ –±—É–¥—Ç–æ —Ç—ã –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ."}
    ]

    response = client.chat.completions.create(
        messages=messages,
        max_tokens=500,  
        model="gpt-3.5-turbo"
    )
    
    return response.choices[0].message["content"]


#====================
#===–ö–æ–º–∞–Ω–¥–∞ /start===
#====================
@dp.message(Command("start"))
async def start_cmd(message: Message, state: FSMContext):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç-–ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ üè°\n–ö–∞–∫—É—é –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å –≤—ã –∏—â–µ—Ç–µ?")
    await state.set_state(SearchState.searching)


#=============================
#===–ü–æ–∏—Å–∫ –æ–±—ä–µ–∫—Ç–æ–≤ —á–µ—Ä–µ–∑ –ò–ò===
#=============================
@dp.message(SearchState.searching)
async def search_properties(message: Message, state: FSMContext):
    user_query = message.text

    docs = knowledge_base.similarity_search(user_query, 3)

    if docs:
        properties = "\n".join([
            f"üè† {doc.metadata.get('filename', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\nüìã {doc.page_content[:200]}..."
            for doc in docs
        ])
    else:
        properties = "–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ."

    response = await generate_ai_response(user_query, properties)
    await message.answer(response)

    for doc in docs:
        file_path = os.path.join(PDF_FOLDER, doc.metadata.get("filename", ""))
        if os.path.exists(file_path):
            pdf = FSInputFile(file_path)
            await message.answer_document(pdf)

    await message.answer("–ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞—Ç—å —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞.")

#=================
#===–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞===
#=================
async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
