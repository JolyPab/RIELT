import os
import asyncio
import logging
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from PyPDF2 import PdfReader
import torch
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from openai import OpenAI
from aiogram import Router

#===–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è===
logging.basicConfig(level=logging.DEBUG)

#===–ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è===
load_dotenv()
TOKEN = os.getenv("TELEGRAM_TOKEN")
PDF_FOLDER = os.getenv("PDF_FOLDER")

if not TOKEN:
    raise ValueError("–û—à–∏–±–∫–∞: TELEGRAM_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env!")
if not PDF_FOLDER:
    raise ValueError("–û—à–∏–±–∫–∞: PDF_FOLDER –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env!")

#====–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞===
bot = Bot(token=TOKEN)
dp = Dispatcher()

#===–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI===
client = OpenAI(
    api_key="sk-aitunnel-v66J7WhiyFEFEu2fQ32zLxgdh77VudJn",
    base_url="https://api.aitunnel.ru/v1/"
)

#===–°–æ—Å—Ç–æ—è–Ω–∏—è –±–æ—Ç–∞===
class SearchState(StatesGroup):
    searching = State()
    last_result = State()  
    dialog_context = State()

#===–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è===
async def extract_criteria(user_query):
    messages = [
        {"role": "system", "content": "Eres asistente de bienes ra√≠ces. Selecciona de la consulta los criterios (presupuesto, n√∫mero de habitaciones, piscina, √°rea, etc.). Responde con un objeto JSON."},
        {"role": "user", "content": f"El cliente escribi√≥: {user_query}"}
    ]

    response = client.chat.completions.create(
        messages=messages,
        max_tokens=100,
        model="gpt-4o-mini"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à—É –º–æ–¥–µ–ª—å
    )

    criteria_text = response.choices[0].message.content
    try:
        criteria = eval(criteria_text)
    except Exception:
        criteria = {}

    return criteria

#===–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ–±—ä–µ–∫—Ç–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏===
async def extract_property_details(text):
    messages = [
        {"role": "system", "content": "Eres asistente de bienes ra√≠ces. Extraiga del texto informaci√≥n sobre el precio, el n√∫mero de habitaciones, la disponibilidad de piscina y otras caracter√≠sticas. Responde con un objeto JSON."},
        {"role": "user", "content": f"Texto: {text}"}
    ]

    response = client.chat.completions.create(
        messages=messages,
        max_tokens=200,
        model="gpt-4o-mini"  
    )

    details_text = response.choices[0].message.content
    try:
        details = eval(details_text)
    except Exception:
        details = {}

    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–π
    if "pool" not in details:
        details["pool"] = False  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –±–∞—Å—Å–µ–π–Ω –Ω–µ —É–∫–∞–∑–∞–Ω
    if "rooms" not in details:
        details["rooms"] = 0  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç –Ω–µ —É–∫–∞–∑–∞–Ω–æ
    if "price" not in details:
        details["price"] = float("inf")  

    return details

#===–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏===
async def create_embeddings():
    print("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏...")

    property_data = []
    metadata = []

    for filename in os.listdir(PDF_FOLDER):
        if filename.endswith(".pdf"):
            pdf_path = os.path.join(PDF_FOLDER, filename)
            pdf_reader = PdfReader(pdf_path)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()

            property_data.append(text)
            metadata.append({"filename": filename})

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=100,
        length_function=len
    )

    chunks = []
    meta_list = []
    for text, meta in zip(property_data, metadata):
        prop_chunks = text_splitter.split_text(text)
        chunks.extend(prop_chunks)
        meta_list.extend([meta] * len(prop_chunks))

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={"device": "cuda" if torch.cuda.is_available() else "cpu"}
    )

    knowledge_base = FAISS.from_texts(chunks, embeddings, metadatas=meta_list)
    print("‚úÖ –ë–∞–∑–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    return knowledge_base

#===–°–æ–∑–¥–∞—ë–º —Ä–æ—É—Ç–µ—Ä===
router = Router()

#===–ö–æ–º–∞–Ω–¥–∞ /start===
@router.message(Command("start"))
async def start_cmd(message: Message, state: FSMContext):
    await state.clear()  
    await message.answer("Hola! Soy Angela, tu asistente de bienes ra√≠ces. üè°\n Qu√© tipo de propiedad est√°s buscando?")
    await state.set_state(SearchState.searching)


#=====================================
#===–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è===
#=====================================
@router.message(SearchState.searching)
async def handle_search(message: Message, state: FSMContext):
    user_query = message.text

    #===–∫—Ä–∏—Ç–µ—Ä–∏–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞===
    criteria = await extract_criteria(user_query)
    await state.update_data(user_criteria=criteria)

    #===–ø–æ–∏—Å–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –±–∞–∑–µ FAISS===
    docs = knowledge_base.similarity_search(user_query, k=10) if knowledge_base else []
    print(f"–ù–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {len(docs)}")  # –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥

    #===–§–∏–ª—å—Ç—Ä –æ–±—ä–µ–∫—Ç–∞ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º===
    filtered_properties = []
    for doc in docs:
        details = await extract_property_details(doc.page_content)

        #===—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–±—ä–µ–∫—Ç–∞ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
        if (details.get("price", float("inf")) <= criteria.get("budget", float("inf")) and
            details.get("rooms", 0) >= criteria.get("rooms", 0)):
            filtered_properties.append(doc)

    if filtered_properties:
        #==–ø–æ—Å–ª–µ–¥–Ω–∏–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç===
        await state.update_data(last_result=filtered_properties[0])

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        properties_text = "\n\n".join([
            f"üè† *{doc.metadata.get('filename', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}*\nüìã {doc.page_content[:250]}..."
            for doc in filtered_properties
        ])

        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
        data = await state.get_data()
        context = data.get("dialog_context", [])

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        response = await generate_ai_response(user_query, properties_text, context)

        #===–∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞===
        context.append({"role": "user", "content": user_query})
        context.append({"role": "assistant", "content": response})
        await state.update_data(dialog_context=context)
    else:
        response = "üòï No encontr√© las opciones adecuadas. Intenta refinar la consulta."

    await message.answer(response, parse_mode="Markdown")


#=======================================
#===–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏===
#=======================================
@router.message(lambda message: any(keyword in message.text.lower() for keyword in ["m√°s", "dime", "qu√© inmueble", "precio", "costo"]))
async def handle_details(message: Message, state: FSMContext):
    data = await state.get_data()
    last_property = data.get("last_result")

    if last_property:
        #===–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º –Ω–∞–π–¥–µ–Ω–Ω–æ–º –æ–±—ä–µ–∫—Ç–µ===
        details = await extract_property_details(last_property.page_content)

        #===–æ—Ç–≤–µ—Ç===
        response = f"üìå Aqu√≠ est√°n los detalles sobre {last_property.metadata.get('filename', 'objeto desconocido')}:\n\n"
        
        if "price" in details:
            response += f"üí∞ Precio: {details['price']} MXN\n"
        if "rooms" in details:
            response += f"üõèÔ∏è Habitaci√≥n: {details['rooms']}\n"
        if "location" in details:
            response += f"üìç √Årea: {details['location']}\n"
        if "pool" in details:
            response += f"üèä Piscina: {'–µ—Å—Ç—å' if details['pool'] else '–Ω–µ—Ç'}\n"
        
        #===—Ç–µ–∫—Å—Ç –æ–±—ä–µ–∫—Ç–∞===
        response += f"\nüìã Descripci√≥n: {last_property.page_content[:500]}..."
    else:
        response = "üòï No recuerdo el √∫ltimo objeto encontrado. Intente buscar de nuevo."

    await message.answer(response)

#===–§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ GPT===
async def generate_ai_response(user_query, properties, context):
    messages = [
        {"role": "system", "content": "Eres un agente inmobiliario profesional. Responda de manera concisa e informativa utilizando los datos inmobiliarios que se le proporcionan. No d√© consejos generales si hay datos espec√≠ficos."},
        *context,
        {"role": "user", "content": user_query},
        {"role": "assistant", "content": f"Aqu√≠ hay algunas opciones apropiadas:\n\n{properties}"},
        {"role": "user", "content": "Escribe una respuesta al estilo de la comunicaci√≥n empresarial"}
    ]

    response = client.chat.completions.create(
        messages=messages,
        max_tokens=500,
        model="gpt-4o-mini"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à—É –º–æ–¥–µ–ª—å
    )

    return response.choices[0].message.content

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    global knowledge_base
    print("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏...")
    knowledge_base = await create_embeddings()
    print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º Telegram-–±–æ—Ç–∞...")

    dp.include_router(router)
    await dp.start_polling(bot)

if __name__ == "__main__":
    print("üü¢ –ó–∞–ø—É—Å–∫–∞–µ–º event loop...")
    asyncio.run(main())